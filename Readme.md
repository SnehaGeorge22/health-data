# ğŸ¥ CMS Medicare Claims Data Pipeline (AWS End-to-End)

An end-to-end **cloud-native data engineering pipeline** built on **AWS**, using **CMS Medicare DE-SynPUF** data to demonstrate scalable ingestion, transformation, orchestration, and analytics using modern data lakehouse principles.

---

## ğŸš€ Project Highlights

* âœ… Real-world **healthcare claims data** (CMS Medicare)
* âœ… **Bronze â†’ Silver â†’ Gold** layered architecture
* âœ… Event-driven orchestration with **AWS Step Functions**
* âœ… Large-scale ETL using **AWS Glue (PySpark)**
* âœ… Dimensional modeling (Facts & Dimensions)
* âœ… Athena-ready analytics layer
* âœ… Production-grade error handling & schema management

This project mirrors how **enterprise healthcare data platforms** are designed in real production environments.

---

## ğŸ“Š Dataset Overview

**CMS DE-SynPUF (Synthetic Public Use File)**

* **Source**: Centers for Medicare & Medicaid Services (CMS)
* **Data Type**: De-identified Medicare claims
* **Time Period**: 2008â€“2010
* **Scale**: ~116,000 beneficiaries (Sample 1)
* **Files Included**:

  * Beneficiary Summary
  * Inpatient Claims
  * Outpatient Claims
  * Carrier Claims
  * Prescription Drug Events
* **Compliance**: HIPAA-safe, synthetic data

ğŸ”— Official dataset:
[https://www.cms.gov/data-research/statistics-trends-and-reports/medicare-claims-synthetic-public-use-files](https://www.cms.gov/data-research/statistics-trends-and-reports/medicare-claims-synthetic-public-use-files)

---

## ğŸ—ï¸ Architecture Overview

```
S3 (Raw Landing Zone)
        â†“
Glue Crawlers (Schema Discovery)
        â†“
Bronze Layer (Raw + Audit)
        â†“
Glue Crawlers (Schema Discovery)
        â†“
Silver Layer (Cleaned, Standardized, SCD-2)
        â†“
Glue Crawlers (Schema Discovery)
        â†“
Gold Layer (Dimensional Model)
        â†“
Glue Crawlers (Schema Discovery)
        â†“        
Athena (Analytics & BI)
```

### Key AWS Services Used

* **Amazon S3** â€“ Data lake storage
* **AWS Glue** â€“ ETL + Data Catalog
* **AWS Step Functions** â€“ Workflow orchestration
* **AWS Lambda** â€“ Validation & automation
* **Amazon Athena** â€“ SQL analytics
* **Amazon SNS** â€“ Notifications
* **Amazon IAM** â€“ Access Management
* **Amazon Cloudwatch** â€“ Logs and Audit

---

## ğŸ§± Data Layers Explained

### ğŸ¥‰ Bronze Layer

* Raw ingestion from S3 landing zone
* Schema inference via Glue Crawlers
* Deduplication & audit columns
* Immutable historical storage

### ğŸ¥ˆ Silver Layer

* Data cleansing & standardization
* Business rules applied
* **SCD Type-2** implementation for Beneficiaries
* Normalized tables:

  * `beneficiary_clean`
  * `claims_unified`
  * `diagnosis_normalized`
  * `procedure_normalized`

### ğŸ¥‡ Gold Layer

* Analytics-ready dimensional model
* Star schema design
* Optimized for Athena queries

**Dimensions**

* `dim_patient` (SCD-2)
* `dim_provider`
* `dim_diagnosis`
* `dim_date`

**Facts**

* `fact_claims`
* `fact_prescriptions`
* `patient_summary`

---

## ğŸ”„ Orchestration (Step Functions)

The pipeline is orchestrated using **AWS Step Functions**:

1. Data validation (Lambda)
2. Glue Crawlers (raw)
3. Bronze ETL
4. Bronze crawlers (parallel)
5. Silver ETL
6. Silver crawlers (parallel)
7. Gold ETL
8. Gold crawlers (parallel)
9. Data quality checks
10. Success notification (SNS)

Parallel execution is used where possible to improve performance and reduce cost.

---

## ğŸ§ª Data Quality & Reliability

* Schema validation before processing
* Type-safe Spark transformations
* Explicit casting to avoid schema drift
* Referential integrity checks in Gold layer
* Audit columns for lineage tracking

---

## ğŸ“ˆ Example Analytics (Athena)

* Total claims cost by year
* Chronic condition prevalence by state
* Prescription cost trends
* Patient-level utilization summary
* Provider-level claim volume

---

## âš ï¸ Cost Management Note

This project was intentionally **paused before full-scale reprocessing** to stay within **AWS Free Tier limits**.

> This reflects real-world engineering decisions where cost-awareness is critical.

---

## ğŸ§  Key Learnings

* Schema drift is the #1 failure point in large Spark pipelines
* Glue Crawlers require **careful partition strategy**
* SCD Type-2 is non-trivial at scale
* Column ambiguity and type mismatches are common Spark pitfalls
* Parallel orchestration significantly reduces pipeline runtime
* Cost monitoring is as important as performance

---

## ğŸ› ï¸ Tech Stack

* **Languages**: Python, PySpark, SQL
* **Cloud**: AWS (S3, Glue, Lambda, Step Functions, Athena)
* **Data Modeling**: Star Schema, SCD-2
* **Orchestration**: Step Functions

---

## ğŸ“Œ Future Enhancements

* Add CI/CD for Glue jobs
* Integrate dbt for Gold modeling
* Implement Great Expectations for DQ
* Add QuickSight dashboards
* Enable incremental processing with bookmarks

---

## ğŸ‘¤ Author

**Sneha George Gnanakalavathy**
Data Engineer | Data Scientist
ğŸ“ United Kingdom

ğŸ”— Portfolio: [https://snehageorge22.github.io](https://snehageorge22.github.io)
ğŸ”— LinkedIn: [https://www.linkedin.com/in/snehageorge](https://www.linkedin.com/in/snehageorge)
ğŸ”— GitHub: [https://github.com/snehageorge22](https://github.com/snehageorge22)
